
---

# (1) Minimal repo tree

```
ncfd/                           # Near-Certain Failure Detector (monorepo root)
├─ pyproject.toml
├─ Makefile
├─ .env.example
├─ .gitignore
├─ README.md
├─ config/
│  └─ config.yaml               # Non-secret config (profiles: local/staging/prod)
├─ alembic.ini                  # Alembic DB migrations
├─ alembic/
│  ├─ env.py
│  └─ versions/                 # Autogenerated migration scripts
├─ scripts/
│  ├─ ingest_ctgov.py           # CLI entry to run CT.gov ingest (Prefect flow)
│  └─ db_migrate.py             # Optional helper wrapper for Alembic
├─ src/
│  └─ ncfd/
│     ├─ __init__.py
│     ├─ config.py              # Pydantic Settings: merge config.yaml + .env
│     ├─ logging.py             # Structured logging setup
│     ├─ db/
│     │  ├─ __init__.py
│     │  ├─ models.py           # SQLAlchemy models for core tables
│     │  ├─ session.py          # Session/engine helpers (PG + DuckDB)
│     │  └─ schema_sql/         # Raw SQL templates (e.g., views, indices)
│     ├─ storage/
│     │  ├─ __init__.py
│     │  ├─ s3.py               # Object storage (S3/MinIO) wrapper
│     │  └─ fs.py               # Local dev fallback
│     ├─ ingest/
│     │  ├─ __init__.py
│     │  ├─ ctgov.py            # Registry ingest + version history capture
│     │  ├─ sec.py              # 8-K/10-K/10-Q fetch + metadata
│     │  ├─ pubs.py             # PubMed/OpenAlex/PMC/Europe PMC
│     │  ├─ patents.py          # USPTO/assignment + INPADOC family data
│     │  └─ utils.py
│     ├─ extract/
│     │  ├─ __init__.py
│     │  ├─ lanextract_adapter.py # LangExtract glue → Study Card JSON
│     │  └─ rules.py            # Any hand-written extractors
│     ├─ mapping/
│     │  ├─ __init__.py
│     │  ├─ deterministic.py    # CIK, exchange whitelist, sub→parent
│     │  ├─ probabilistic.py    # High-precision resolver (name/domain/alias)
│     │  └─ asset_backstop.py   # Asset/INN→issuer via PRs/8-Ks
│     ├─ signals/
│     │  ├─ __init__.py
│     │  ├─ primitives.py       # S1–S9 implementations (+ unit parsers)
│     │  └─ gates.py            # G1–G4 (co-dependent logic)
│     ├─ scoring/
│     │  ├─ __init__.py
│     │  ├─ calibrate.py        # Likelihood ratio calibration utilities
│     │  └─ score.py            # Prior→Posterior, stop rules, traceability
│     ├─ flows/
│     │  ├─ __init__.py
│     │  ├─ pipeline.py         # Prefect flow: ingest→extract→map→signal→score
│     │  └─ tasks.py            # Prefect tasks (idempotent, retryable)
│     └─ api/                   # (Optional) FastAPI for service endpoints
│        ├─ __init__.py
│        └─ main.py
├─ data/                        # Local dev only (gitignored) - DuckDB, tmp blobs
│  ├─ duckdb/
│  └─ raw/
└─ tests/
   ├─ conftest.py
   ├─ test_config.py
   ├─ test_mapping_deterministic.py
   ├─ test_mapping_probabilistic.py
   ├─ test_mapping_asset_backstop.py
   ├─ test_ctgov_version_diff.py
   ├─ test_signals_primitives.py
   ├─ test_gates.py
   ├─ test_scoring.py
   └─ test_ingest_idempotency.py
```

**Rationales (short):**

* `src/ncfd/*`: Domain-first layering keeps business logic isolated and testable.
* `ingest/*`: All fetchers live here; easy to stub + rate-limit centrally.
* `extract/*`: Normalizes heterogeneous docs into Study Cards (traceable spans).
* `mapping/*`: Three-stage sponsor→ticker mapping; independently testable.
* `signals/*` & `gates/*`: Enforces your “few, very high-confidence” philosophy.
* `scoring/*`: Single place for LRs, priors, stop rules, and P\_fail math.
* `flows/*`: Orchestration only—no business logic.
* `db/*`: Models + sessions; Alembic handles schema diffs.
* `storage/*`: Pluggable S3/FS; local dev works without cloud.
* `api/`: Optional service surface when you’re ready (kept out of the critical path).
* `tests/*`: Mirrors architecture boundaries for crisp coverage.
* `alembic/*`: Deterministic migrations, required for CI + reproducibility.

---

# (2) `pyproject.toml`

```toml
[build-system]
requires = ["setuptools>=68", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "ncfd"
version = "0.1.0"
description = "Near-Certain Failure Detector for US-listed biotech pivotal trials"
readme = "README.md"
requires-python = ">=3.11"
license = {text = "MIT"}
authors = [{ name = "Your Team" }]

dependencies = [
  "requests>=2.31",
  "pydantic>=2.6",
  "pydantic-settings>=2.2",
  "SQLAlchemy>=2.0",
  "psycopg2-binary>=2.9",
  "duckdb>=1.0",
  "prefect>=2.16",
  "beautifulsoup4>=4.12",
  "lxml>=5.0",
  "PyYAML>=6.0",
  "alembic>=1.13",
  "python-dateutil>=2.9",
  "tqdm>=4.66",
  "uvloop>=0.19; platform_system != 'Windows'",
]

[project.optional-dependencies]
api = ["fastapi>=0.112", "uvicorn[standard]>=0.30"]
extract = ["langextract>=0"]  # if private/not on PyPI, pin as VCS in your env

dev = [
  "pytest>=8.0",
  "pytest-cov>=5.0",
  "freezegun>=1.5",
  "ruff>=0.5",
  "black>=24.4",
  "mypy>=1.10",
  "types-requests",
  "pre-commit>=3.7",
]

[tool.setuptools.packages.find]
where = ["src"]

[tool.ruff]
line-length = 100
select = ["E","F","I","B","UP"]
target-version = "py311"

[tool.black]
line-length = 100
target-version = ["py311"]

[tool.mypy]
python_version = "3.11"
strict = true
plugins = []

[tool.pytest.ini_options]
testpaths = ["tests"]
addopts = "-q --disable-warnings --maxfail=1"

[tool.coverage.run]
source = ["src/ncfd"]
branch = true

[tool.coverage.report]
skip_empty = true
```

---

# (3) `.env.example`

```bash
# --- App profile ---
CONFIG_PROFILE=local                 # local|staging|prod

# --- Postgres (preferred: DSN; or individual vars if you like) ---
POSTGRES_DSN=postgresql+psycopg2://ncfd:ncfd@localhost:5432/ncfd
# PGHOST=localhost
# PGPORT=5432
# PGDATABASE=ncfd
# PGUSER=ncfd
# PGPASSWORD=ncfd

# --- DuckDB ---
DUCKDB_PATH=./data/duckdb/analytics.duckdb

# --- Object storage (S3/MinIO) ---
S3_ENDPOINT_URL=http://localhost:9000
S3_REGION=us-east-1
S3_BUCKET=ncfd-raw
S3_ACCESS_KEY=minioadmin
S3_SECRET_KEY=minioadmin
S3_USE_SSL=false

# --- External sources (non-secret where possible) ---
UNPAYWALL_EMAIL=you@example.com
OPENALEX_EMAIL=you@example.com

# SEC and NCBI are rate-limited; identify politely
SEC_USER_AGENT=ncfd-bot you@example.com
NCBI_TOOL=ncfd
NCBI_EMAIL=you@example.com

# --- Prefect (optional cloud) ---
PREFECT_API_URL=
PREFECT_API_KEY=

# --- API (optional) ---
API_HOST=0.0.0.0
API_PORT=8000
```

---

# (4) `config.yaml` (key structure)

```yaml
# config/config.yaml

profile_defaults: &defaults
  logging:
    level: INFO
    json: true

  database:
    # Prefer DSN from env; these serve as fallbacks
    dsn: ${POSTGRES_DSN}
    pool_size: 10
    pool_timeout_s: 30

  duckdb:
    path: ${DUCKDB_PATH}

  storage:
    kind: s3            # s3|fs
    s3:
      endpoint_url: ${S3_ENDPOINT_URL}
      region: ${S3_REGION}
      bucket: ${S3_BUCKET}
      access_key: ${S3_ACCESS_KEY}
      secret_key: ${S3_SECRET_KEY}
      use_ssl: ${S3_USE_SSL}
    fs:
      root: ./data/raw

  ingestion:
    ctgov:
      base_url: https://clinicaltrials.gov/api/v2
      backfill_start: "2000-01-01"
      batch_size: 500
      sleep_ms: 200
      capture_version_history: true
    sec:
      rate_limit_per_min: 6
      user_agent: ${SEC_USER_AGENT}
    pubs:
      unpaywall_email: ${UNPAYWALL_EMAIL}
      openalex_email: ${OPENALEX_EMAIL}
    patents:
      uspto_endpoint: https://developer.uspto.gov/ds-api
      inpadoc_family: true

  entity_mapping:
    exchanges_whitelist: ["NYSE","NASDAQ","NYSE American","OTCQX","OTCQB"]
    name_match_threshold: 0.98
    alias_boost: 0.02
    domain_match_required: true
    asset_backstop_enabled: true

  extraction:
    use_langextract: true
    max_pages: 50
    keep_spans: true

  signals:
    p_value_cusp_range: [0.045, 0.050]
    power_min_threshold: 0.70
    effect_size_graveyard_percentile: 0.75
    dropout_imbalance_threshold: 0.20
    multiplicity_control_required: true

  gates:
    # Gates are co-dependent; define which primitives are required
    G1_alpha_meltdown: {requires: ["S1","S2"]}
    G2_analysis_gaming: {requires: ["S3","S4"]}
    G3_plausibility: {requires_any: ["S6","S7"], also_requires: ["S5"]}
    G4_p_hacking: {requires: ["S8"], requires_any: ["S1","S3"]}

  scoring:
    prior_failure_rate: 0.55               # π0 baseline for universe
    likelihood_ratios:
      G1: 5.0
      G2: 6.0
      G3: 4.0
      G4: 3.5
      # primitives default near 1.0 unless calibrated
    stop_rules:
      endpoint_switched_after_LPR: 0.97    # set P_fail
      pp_only_success_with_itt_missing_gt: 0.97
      unblinded_subjective_primary_when_blinding_feasible: 0.97
    freeze_window_days: 14

  evaluation:
    precision_at_k: [1, 3]
    pfail_thresholds: [0.8, 0.9, 0.95]

local:
  <<: *defaults

staging:
  <<: *defaults
  logging:
    level: INFO

prod:
  <<: *defaults
  logging:
    level: WARNING
```

**Config strategy:**

* `pydantic-settings` loads `.env` first, then merges `config.yaml` (profile chosen by `CONFIG_PROFILE`), with **env vars taking precedence**. Secrets live in `.env` or your secret manager; YAML stays non-sensitive and versioned.

---

# (5) `Makefile`

```make
PY?=python3
VENV=.venv
PIP=$(VENV)/bin/pip
PYTHON=$(VENV)/bin/python

.PHONY: setup fmt lint type test db_migrate ingest_ctgov run_all alembic_init

setup:
	$(PY) -m venv $(VENV)
	$(PIP) install -U pip
	$(PIP) install -e .[dev]
	$(VENV)/bin/pre-commit install
	@echo "✅ venv ready. Activate with: source $(VENV)/bin/activate"

fmt:
	$(VENV)/bin/ruff check --fix .
	$(VENV)/bin/black .

lint:
	$(VENV)/bin/ruff check .
	$(VENV)/bin/black --check .

type:
	$(VENV)/bin/mypy src

test:
	CONFIG_PROFILE=local $(VENV)/bin/pytest -q

alembic_init:
	@# one-time (if you haven't created migrations folder)
	$(VENV)/bin/alembic init alembic

db_migrate:
	@# generate new revision from models (edit message as needed)
	$(VENV)/bin/alembic revision --autogenerate -m "auto"
	@# apply latest migrations
	$(VENV)/bin/alembic upgrade head

ingest_ctgov:
	CONFIG_PROFILE=local $(PYTHON) scripts/ingest_ctgov.py --since 2000-01-01

run_all:
	make db_migrate
	make ingest_ctgov
```

---

## (Bonus) Minimal CI (GitHub Actions)

*Adds deterministic checks + spins Postgres for tests.*

```
.github/
└─ workflows/
   └─ ci.yml
```

```yaml
name: ci

on:
  push: { branches: ["main"] }
  pull_request:

jobs:
  test:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: ncfd
          POSTGRES_PASSWORD: ncfd
          POSTGRES_DB: ncfd
        ports: ["5432:5432"]
        options: >-
          --health-cmd="pg_isready -U ncfd" --health-interval=5s
          --health-timeout=5s --health-retries=10
      minio:
        image: minio/minio:latest
        ports: ["9000:9000","9001:9001"]
        env:
          MINIO_ROOT_USER: minioadmin
          MINIO_ROOT_PASSWORD: minioadmin
        options: --health-cmd="curl -f http://localhost:9000/minio/health/ready || exit 1" --health-interval=5s --health-retries=10
        command: server /data --console-address ":9001"

    strategy:
      matrix:
        python-version: ["3.11", "3.12"]

    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: ${{ matrix.python-version }} }

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-${{ matrix.python-version }}-${{ hashFiles('pyproject.toml') }}

      - name: Install
        run: |
          python -m venv .venv
          . .venv/bin/activate
          pip install -U pip
          pip install -e .[dev]
      - name: Env file
        run: |
          cat > .env <<'EOF'
          CONFIG_PROFILE=local
          POSTGRES_DSN=postgresql+psycopg2://ncfd:ncfd@localhost:5432/ncfd
          DUCKDB_PATH=./data/duckdb/ci.duckdb
          S3_ENDPOINT_URL=http://localhost:9000
          S3_REGION=us-east-1
          S3_BUCKET=ncfd-raw
          S3_ACCESS_KEY=minioadmin
          S3_SECRET_KEY=minioadmin
          S3_USE_SSL=false
          UNPAYWALL_EMAIL=ci@example.com
          OPENALEX_EMAIL=ci@example.com
          SEC_USER_AGENT=ncfd-ci ci@example.com
          EOF
      - name: DB migrate
        run: |
          . .venv/bin/activate
          alembic upgrade head
      - name: Lint + Type + Test
        run: |
          . .venv/bin/activate
          ruff check .
          black --check .
          mypy src
          pytest -q
```

---

## Initial unit tests to add (names map to files shown)

* `test_config.py`

  * Loads YAML + .env merge; env precedence; profile switching (local/staging/prod).
* `test_mapping_deterministic.py`

  * CIK→issuer exact match; exchange whitelist enforced; subsidiary→parent roll-up.
* `test_mapping_probabilistic.py`

  * High-precision resolver: name/domain/alias thresholds; rejects near-matches; no false positives.
* `test_mapping_asset_backstop.py`

  * Asset/INN→issuer via PR/8-K chain; handles academia sponsor with publicco asset owner.
* `test_ctgov_version_diff.py`

  * NCT version history captured; detects endpoint text changes; sample size deltas; produces `changes_jsonb`.
* `test_signals_primitives.py`

  * S1 endpoint changed (true/false cases).
  * S2 underpowered: power calc vs claimed Δ (<0.70) with ITT N.
  * S3 subgroup-only win + multiplicity not controlled.
  * S4 ITT neutral/neg vs PP positive with dropout asymmetry ≥20%.
  * S8 p-value cusp ∈ \[0.045,0.050]; S6 multi-interim without alpha spending, etc.
* `test_gates.py`

  * G1 fires only when S1∧S2; G2 with S3∧S4; G3 with S5∧(S7∨S6); G4 with S8∧(S1∨S3).
* `test_scoring.py`

  * Prior→posterior with calibrated LRs; accumulation in log-odds; stop rules force P\_fail≈0.97.
  * Freeze window (T-14) excludes late docs.
* `test_ingest_idempotency.py`

  * Re-running ingest doesn’t duplicate `trials`, `trial_versions`, `studies` (UPSERT semantics).
* (Optional) `test_storage_backend.py`

  * S3 and FS backends behave equivalently for put/get/list.

---

### Notes on a few implementation details

* **CT.gov version history**: store each snapshot in `trial_versions.raw_jsonb`; compute `changes_jsonb` as normalized diffs (endpoint text, N, analysis plan).
* **Precision bias**: set **high thresholds** for the probabilistic resolver and keep an explicit denylist for common confounders (e.g., legacy shells, homonyms).
* **Traceability**: Study Cards must preserve **page/line spans** and source URLs; every `signal` stores `evidence_span` and `source_study_id`.
* **Stop rules first**: short-circuit scoring when triggered; they dominate the posterior by design.
* **Local-first dev**: FS storage + MinIO service in CI; swap to real S3 in prod via `.env`.

If you want, I can drop in minimal stubs for `config.py`, `db/session.py`, and a `flows/pipeline.py` skeleton next.
