#!/usr/bin/env python3
"""
Comprehensive End-to-End Pipeline Test.

This script tests the full CT.gov ingestion pipeline with real data:
1. Clean database setup
2. Limited CT.gov ingestion (real trials)
3. Data quality verification
4. Study card creation
5. Signal detection
6. Full analysis workflow

Uses a single database session throughout to avoid SQLAlchemy detachment issues.
"""

import os
import sys
import logging
import json
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Any

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from ncfd.pipeline.ctgov_pipeline import CtgovPipeline
from ncfd.db.session import get_session
from ncfd.db.models import Trial, TrialVersion, Company, Study

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class E2ETestResults:
    """Container for end-to-end test results."""
    
    def __init__(self):
        self.start_time = datetime.utcnow()
        self.ingestion_results = {}
        self.data_quality_results = {}
        self.study_card_results = {}
        self.signal_detection_results = {}
        self.errors = []
        self.warnings = []
    
    def add_error(self, error: str):
        self.errors.append(error)
        logger.error(error)
    
    def add_warning(self, warning: str):
        self.warnings.append(warning)
        logger.warning(warning)
    
    def get_summary(self) -> Dict[str, Any]:
        duration = (datetime.utcnow() - self.start_time).total_seconds()
        return {
            'duration_seconds': duration,
            'success': len(self.errors) == 0,
            'ingestion': self.ingestion_results,
            'data_quality': self.data_quality_results,
            'study_cards': self.study_card_results,
            'signal_detection': self.signal_detection_results,
            'errors': self.errors,
            'warnings': self.warnings
        }

def test_database_state(session) -> Dict[str, int]:
    """Test initial database state."""
    logger.info("üîç Checking initial database state...")
    
    try:
        initial_trials = session.query(Trial).count()
        initial_versions = session.query(TrialVersion).count()
        initial_companies = session.query(Company).count()
        
        # Check if studies table exists (it might not be created yet)
        try:
            initial_studies = session.query(Study).count()
        except Exception as e:
            logger.warning(f"Studies table not available: {e}")
            initial_studies = 0
        
        state = {
            'trials': initial_trials,
            'versions': initial_versions,
            'companies': initial_companies,
            'studies': initial_studies
        }
        
        logger.info(f"üìä Initial state: {initial_trials} trials, {initial_versions} versions, {initial_companies} companies")
        return state
        
    except Exception as e:
        logger.error(f"‚ùå Database state check failed: {e}")
        return {'error': str(e)}

def test_ctgov_ingestion(session, max_trials: int = 15) -> Dict[str, Any]:
    """Test CT.gov ingestion with limited real dataset."""
    logger.info(f"üöÄ Starting CT.gov ingestion test (max {max_trials} trials)...")
    
    # Configuration for comprehensive testing
    config = {
        'max_studies_per_run': max_trials,
        'batch_size': 10,
        'default_since_days': 60,  # Look back 60 days for more variety
        'focus_phases': ['PHASE2', 'PHASE3', 'PHASE2_PHASE3'],
        'focus_intervention_types': ['DRUG', 'BIOLOGICAL'],
        'focus_study_types': ['INTERVENTIONAL'],
        'change_detection_enabled': True,
        'validation_enabled': True
    }
    
    try:
        # Initialize pipeline
        pipeline = CtgovPipeline(config=config)
        
        # Run limited ingestion with variety of trials
        result = pipeline.run_limited_ingestion(
            max_studies=max_trials,
            since_date=(datetime.now() - timedelta(days=60)).strftime('%Y-%m-%d'),
            phases=['PHASE2', 'PHASE3'],
            statuses=['RECRUITING', 'ACTIVE_NOT_RECRUITING', 'COMPLETED']
        )
        
        return {
            'success': result.success,
            'trials_processed': result.trials_processed,
            'trials_new': result.trials_new,
            'trials_updated': result.trials_updated,
            'changes_detected': result.changes_detected,
            'processing_time': result.processing_time_seconds,
            'errors': result.errors
        }
        
    except Exception as e:
        logger.error(f"‚ùå CT.gov ingestion failed: {e}")
        return {
            'success': False,
            'error': str(e),
            'trials_processed': 0
        }

def analyze_data_quality(session) -> Dict[str, Any]:
    """Analyze the quality of ingested trial data."""
    logger.info("üîç Analyzing data quality...")
    
    try:
        # Get recent trials
        recent_trials = session.query(Trial).order_by(Trial.last_seen_at.desc()).limit(20).all()
        
        quality_metrics = {
            'total_trials_analyzed': len(recent_trials),
            'trials_with_sponsor': 0,
            'trials_with_phase': 0,
            'trials_with_status': 0,
            'trials_with_title': 0,
            'trials_with_versions': 0,
            'phase_distribution': {},
            'status_distribution': {},
            'sponsor_variety': set()
        }
        
        for trial in recent_trials:
            # Check basic fields
            if trial.sponsor_text:
                quality_metrics['trials_with_sponsor'] += 1
                quality_metrics['sponsor_variety'].add(trial.sponsor_text)
            
            if trial.phase:
                quality_metrics['trials_with_phase'] += 1
                phase = trial.phase
                quality_metrics['phase_distribution'][phase] = quality_metrics['phase_distribution'].get(phase, 0) + 1
            
            if trial.status:
                quality_metrics['trials_with_status'] += 1
                status = trial.status
                quality_metrics['status_distribution'][status] = quality_metrics['status_distribution'].get(status, 0) + 1
            
            if trial.brief_title or trial.official_title:
                quality_metrics['trials_with_title'] += 1
            
            # Check versions
            if len(trial.versions) > 0:
                quality_metrics['trials_with_versions'] += 1
        
        # Convert set to count
        quality_metrics['unique_sponsors'] = len(quality_metrics['sponsor_variety'])
        del quality_metrics['sponsor_variety']
        
        # Calculate percentages
        total = quality_metrics['total_trials_analyzed']
        if total > 0:
            quality_metrics['completeness_score'] = (
                quality_metrics['trials_with_sponsor'] + 
                quality_metrics['trials_with_phase'] + 
                quality_metrics['trials_with_status'] + 
                quality_metrics['trials_with_title']
            ) / (total * 4)  # 4 key fields
        
        logger.info(f"üìä Data quality: {quality_metrics['completeness_score']:.2%} completeness")
        return quality_metrics
        
    except Exception as e:
        logger.error(f"‚ùå Data quality analysis failed: {e}")
        return {'error': str(e)}

def select_trials_for_study_cards(session, limit: int = 3) -> List[Dict[str, Any]]:
    """Select diverse trials for study card creation."""
    logger.info(f"üéØ Selecting {limit} trials for study card creation...")
    
    try:
        # Get trials with good data quality - return as dictionaries to avoid session issues
        trials = session.query(Trial).filter(
            Trial.sponsor_text.isnot(None),
            Trial.phase.isnot(None),
            Trial.status.isnot(None)
        ).order_by(Trial.last_seen_at.desc()).limit(limit * 2).all()
        
        # Convert to dictionaries to avoid session detachment issues
        trial_dicts = []
        for trial in trials:
            trial_dict = {
                'nct_id': trial.nct_id,
                'trial_id': trial.trial_id,
                'brief_title': trial.brief_title,
                'official_title': trial.official_title,
                'sponsor_text': trial.sponsor_text,
                'phase': trial.phase,
                'status': trial.status,
                'indication': trial.indication,
                'is_pivotal': trial.is_pivotal,
                'primary_endpoint_text': trial.primary_endpoint_text,
                'est_primary_completion_date': trial.est_primary_completion_date,
                'first_posted_date': trial.first_posted_date,
                'last_update_posted_date': trial.last_update_posted_date,
                'intervention_types': trial.intervention_types,
                'last_seen_at': trial.last_seen_at,
                'current_sha256': trial.current_sha256
            }
            trial_dicts.append(trial_dict)
        
        # Select diverse trials (different phases, sponsors)
        selected = []
        phases_seen = set()
        sponsors_seen = set()
        
        for trial_dict in trial_dicts:
            # Prefer trials with different phases and sponsors
            if (len(selected) < limit and 
                (trial_dict['phase'] not in phases_seen or trial_dict['sponsor_text'] not in sponsors_seen)):
                selected.append(trial_dict)
                phases_seen.add(trial_dict['phase'])
                sponsors_seen.add(trial_dict['sponsor_text'])
        
        # Fill remaining slots if needed
        while len(selected) < limit and len(selected) < len(trial_dicts):
            for trial_dict in trial_dicts:
                if trial_dict not in selected:
                    selected.append(trial_dict)
                    break
        
        logger.info(f"‚úÖ Selected {len(selected)} trials for study cards")
        for trial_dict in selected:
            title = trial_dict['brief_title'] or trial_dict['official_title'] or 'No title'
            logger.info(f"   - {trial_dict['nct_id']}: {title[:50]}...")
            logger.info(f"     Phase: {trial_dict['phase']}, Status: {trial_dict['status']}, Sponsor: {trial_dict['sponsor_text']}")
        
        return selected
        
    except Exception as e:
        logger.error(f"‚ùå Trial selection failed: {e}")
        return []

def test_study_card_creation(session, trials: List[Dict[str, Any]]) -> Dict[str, Any]:
    """Test study card creation for selected trials."""
    logger.info(f"üìù Testing study card creation for {len(trials)} trials...")
    
    # For now, this is a placeholder since we haven't implemented the study card system yet
    # This would integrate with the LangExtract system mentioned in the spec
    
    study_card_results = {
        'trials_processed': len(trials),
        'cards_created': 0,
        'cards_validated': 0,
        'extraction_quality': {},
        'errors': []
    }
    
    for trial_dict in trials:
        try:
            logger.info(f"üîç Would create study card for {trial_dict['nct_id']}")
            logger.info(f"   - Title: {trial_dict['brief_title'] or trial_dict['official_title'] or 'No title'}")
            logger.info(f"   - Phase: {trial_dict['phase']}, Status: {trial_dict['status']}")
            logger.info(f"   - Sponsor: {trial_dict['sponsor_text']}")
            
            # TODO: Implement actual study card creation
            # This would involve:
            # 1. Extract structured data using LangExtract
            # 2. Validate against JSON schema
            # 3. Store in studies table
            # 4. Calculate coverage and quality metrics
            
            study_card_results['cards_created'] += 1
            
        except Exception as e:
            error_msg = f"Study card creation failed for {trial_dict['nct_id']}: {e}"
            study_card_results['errors'].append(error_msg)
            logger.error(error_msg)
    
    logger.info(f"üìù Study card creation test completed: {study_card_results['cards_created']} cards simulated")
    return study_card_results

def test_signal_detection(session, trials: List[Dict[str, Any]]) -> Dict[str, Any]:
    """Test signal detection on selected trials."""
    logger.info(f"‚ö†Ô∏è Testing signal detection for {len(trials)} trials...")
    
    # Placeholder for signal detection testing
    # This would test the S1-S9 signal detectors mentioned in the spec
    
    signal_results = {
        'trials_analyzed': len(trials),
        'signals_detected': 0,
        'signal_types': {},
        'gates_fired': 0,
        'errors': []
    }
    
    for trial_dict in trials:
        try:
            logger.info(f"üîç Would analyze signals for {trial_dict['nct_id']}")
            logger.info(f"   - Phase: {trial_dict['phase']}, Status: {trial_dict['status']}")
            logger.info(f"   - Sponsor: {trial_dict['sponsor_text']}")
            
            # TODO: Implement actual signal detection
            # This would involve:
            # 1. Run S1-S9 signal detectors
            # 2. Evaluate gates G1-G4
            # 3. Calculate risk scores
            # 4. Store results
            
        except Exception as e:
            error_msg = f"Signal detection failed for {trial_dict['nct_id']}: {e}"
            signal_results['errors'].append(error_msg)
            logger.error(error_msg)
    
    logger.info(f"‚ö†Ô∏è Signal detection test completed: {signal_results['signals_detected']} signals simulated")
    return signal_results

def run_full_e2e_test() -> E2ETestResults:
    """Run the complete end-to-end pipeline test."""
    logger.info("üöÄ Starting Full End-to-End Pipeline Test")
    logger.info("=" * 60)
    
    results = E2ETestResults()
    
    try:
        # Use a single session for the entire test to avoid detachment issues
        with get_session() as session:
            # 1. Check initial database state
            logger.info("\nüìä PHASE 1: Database State Analysis")
            initial_state = test_database_state(session)
            
            # 2. Run CT.gov ingestion
            logger.info("\nüåê PHASE 2: CT.gov Data Ingestion")
            ingestion_results = test_ctgov_ingestion(session, max_trials=15)
            results.ingestion_results = ingestion_results
            
            if not ingestion_results.get('success', False):
                results.add_error("CT.gov ingestion failed")
                return results
            
            # 3. Analyze data quality
            logger.info("\nüîç PHASE 3: Data Quality Analysis")
            quality_results = analyze_data_quality(session)
            results.data_quality_results = quality_results
            
            # 4. Select trials for further testing
            logger.info("\nüéØ PHASE 4: Trial Selection")
            selected_trials = select_trials_for_study_cards(session, limit=3)
            
            if not selected_trials:
                results.add_warning("No trials selected for study card creation")
            
            # 5. Test study card creation
            logger.info("\nüìù PHASE 5: Study Card Creation")
            study_card_results = test_study_card_creation(session, selected_trials)
            results.study_card_results = study_card_results
            
            # 6. Test signal detection
            logger.info("\n‚ö†Ô∏è PHASE 6: Signal Detection")
            signal_results = test_signal_detection(session, selected_trials)
            results.signal_detection_results = signal_results
            
            logger.info("\n‚úÖ End-to-End Test Completed Successfully!")
        
    except Exception as e:
        results.add_error(f"E2E test failed: {e}")
        logger.error(f"‚ùå E2E test failed: {e}", exc_info=True)
    
    return results

def print_final_report(results: E2ETestResults):
    """Print a comprehensive test report."""
    summary = results.get_summary()
    
    logger.info("\n" + "=" * 60)
    logger.info("üìã FINAL END-TO-END TEST REPORT")
    logger.info("=" * 60)
    
    logger.info(f"‚è±Ô∏è  Total Duration: {summary['duration_seconds']:.2f} seconds")
    logger.info(f"‚úÖ Overall Success: {summary['success']}")
    
    # Ingestion Results
    ingestion = summary.get('ingestion', {})
    logger.info(f"\nüåê CT.gov Ingestion:")
    logger.info(f"   - Trials Processed: {ingestion.get('trials_processed', 0)}")
    logger.info(f"   - New Trials: {ingestion.get('trials_new', 0)}")
    logger.info(f"   - Updated Trials: {ingestion.get('trials_updated', 0)}")
    logger.info(f"   - Processing Time: {ingestion.get('processing_time', 0):.2f}s")
    
    # Data Quality Results
    quality = summary.get('data_quality', {})
    logger.info(f"\nüîç Data Quality:")
    logger.info(f"   - Trials Analyzed: {quality.get('total_trials_analyzed', 0)}")
    logger.info(f"   - Completeness Score: {quality.get('completeness_score', 0):.2%}")
    logger.info(f"   - Unique Sponsors: {quality.get('unique_sponsors', 0)}")
    
    # Phase Distribution
    if 'phase_distribution' in quality:
        logger.info(f"   - Phase Distribution: {quality['phase_distribution']}")
    
    # Study Cards
    study_cards = summary.get('study_cards', {})
    logger.info(f"\nüìù Study Cards:")
    logger.info(f"   - Trials Processed: {study_cards.get('trials_processed', 0)}")
    logger.info(f"   - Cards Created: {study_cards.get('cards_created', 0)}")
    
    # Signal Detection
    signals = summary.get('signal_detection', {})
    logger.info(f"\n‚ö†Ô∏è Signal Detection:")
    logger.info(f"   - Trials Analyzed: {signals.get('trials_analyzed', 0)}")
    logger.info(f"   - Signals Detected: {signals.get('signals_detected', 0)}")
    
    # Errors and Warnings
    if summary.get('errors'):
        logger.info(f"\n‚ùå Errors ({len(summary['errors'])}):")
        for error in summary['errors']:
            logger.info(f"   - {error}")
    
    if summary.get('warnings'):
        logger.info(f"\n‚ö†Ô∏è Warnings ({len(summary['warnings'])}):")
        for warning in summary['warnings']:
            logger.info(f"   - {warning}")
    
    logger.info("\n" + "=" * 60)

if __name__ == "__main__":
    # Run the full end-to-end test
    test_results = run_full_e2e_test()
    
    # Print comprehensive report
    print_final_report(test_results)
    
    # Save results to file
    results_file = Path(__file__).parent / f"e2e_test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(results_file, 'w') as f:
        json.dump(test_results.get_summary(), f, indent=2, default=str)
    
    logger.info(f"üìÑ Detailed results saved to: {results_file}")
    
    # Exit with appropriate code
    summary = test_results.get_summary()
    if summary['success']:
        logger.info("üéâ All tests passed!")
        sys.exit(0)
    else:
        logger.error("üí• Some tests failed!")
        sys.exit(1)
